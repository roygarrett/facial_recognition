{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "How to use this facial recognition software:\n",
        "\n",
        "Step 1: Run the \"Installs and Imports\" code cell. This will install and import all of the necessary tools for the program.\n",
        "\n",
        "\n",
        "Step 2: If you would like to add a face to the accepted faces, run the \"Add a face to accepted faces\" code cell. This will open the webcam on the user device. When you are ready to take the photo, click the 'Capture' button.\n",
        "\n",
        "\n",
        "Step 3: If you would like to remove a face from the accepted faces, run the \"Remove a face from accepted faces\" code cell. After asking you for the name of the face you would like to remove, this will remove the indicated face from the accepted faces.\n",
        "\n",
        "\n",
        "Step 4: To verify a user's face, run the \"Verify current user's face\" code cell. This will open the webcam and you will have 5 seconds to position yourself before the photo is taken. The program will then modify your picture to indicate if the face identified in the picture is a member of the accepted faces."
      ],
      "metadata": {
        "id": "u1PYlQlwBpZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installs and Imports:"
      ],
      "metadata": {
        "id": "cKPhCMLMiXRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_facenet\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from google.colab.patches import cv2_imshow\n",
        "from keras_facenet import FaceNet\n",
        "from IPython.display import clear_output\n",
        "import os\n",
        "import matplotlib as plt\n",
        "import pickle\n",
        "from PIL import Image\n",
        "\n",
        "# Load the pre-trained FaceNet model\n",
        "facenet_model = FaceNet()\n",
        "\n",
        "#Ensure correct directory is configured\n",
        "directory = '/content/drive/MyDrive/CS362V/data/faces'\n",
        "if not os.path.exists(directory):\n",
        "  os.makedirs(directory)"
      ],
      "metadata": {
        "id": "PQP62GqMiTCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add a face to accepted faces:"
      ],
      "metadata": {
        "id": "C2yHujyBJE_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to take a photo\n",
        "def take_photo_and_process(filename='photo.jpg', quality=0.8):\n",
        "    # JavaScript code to take a photo\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "          const div = document.createElement('div');\n",
        "          const capture = document.createElement('button');\n",
        "          capture.textContent = 'Capture';\n",
        "          div.appendChild(capture);\n",
        "\n",
        "          const video = document.createElement('video');\n",
        "          video.style.display = 'block';\n",
        "          const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "          document.body.appendChild(div);\n",
        "          div.appendChild(video);\n",
        "          video.srcObject = stream;\n",
        "          await video.play();\n",
        "\n",
        "          // Resize the output to fit the video element.\n",
        "          google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "          // Wait for Capture to be clicked.\n",
        "          await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "          const canvas = document.createElement('canvas');\n",
        "          canvas.width = video.videoWidth;\n",
        "          canvas.height = video.videoHeight;\n",
        "          canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "          stream.getVideoTracks()[0].stop();\n",
        "          div.remove();\n",
        "          return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "\n",
        "    # Display the JavaScript code and capture the photo\n",
        "    display(js)\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "\n",
        "    # Save the photo to a file\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "\n",
        "# Define the function to process the photo using OpenCV\n",
        "def processPhoto(filename):\n",
        "\n",
        "    full_path = os.path.join('/content/drive/MyDrive/CS362V/data/faces', filename)\n",
        "\n",
        "    # Load the cascade\n",
        "    face_cascade_name = '/content/drive/MyDrive/opencv/data/haarcascades/haarcascade_frontalface_alt.xml'\n",
        "    face_cascade = cv.CascadeClassifier()\n",
        "\n",
        "    if not face_cascade.load(cv.samples.findFile(face_cascade_name)):\n",
        "        print('--(!)Error loading face cascade')\n",
        "        return\n",
        "\n",
        "    # Read the image using OpenCV\n",
        "    frame = cv.imread(full_path)\n",
        "\n",
        "    if frame is None:\n",
        "      print(f'--(!)Error reading image: {filename}')\n",
        "      return\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "    frame_gray = cv.equalizeHist(frame_gray)\n",
        "\n",
        "    # Detect faces\n",
        "    faces = face_cascade.detectMultiScale(frame_gray, 1.1, 4)\n",
        "\n",
        "    if len(faces) > 0:\n",
        "      x1, y1, width, height = faces[0]\n",
        "    else:\n",
        "      x1, y1, width, height = 1, 1, 10, 10\n",
        "\n",
        "    x1, y1 = abs(x1), abs(y1)\n",
        "    x2, y2 = x1 + width, y1 + height\n",
        "\n",
        "    gbr = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
        "    gbr = Image.fromarray(gbr)\n",
        "    gbr_array = np.asarray(gbr)\n",
        "\n",
        "    face = gbr_array[y1:y2, x1:x2]\n",
        "\n",
        "    face = Image.fromarray(face)\n",
        "    face = face.resize((160,160))\n",
        "    face = np.asarray(face)\n",
        "\n",
        "    face = np.expand_dims(face, axis=0)\n",
        "    signature = facenet_model.embeddings(face)\n",
        "\n",
        "    return {os.path.splitext(filename)[0] : signature}\n",
        "\n",
        "name = str(input('Enter first name of face to add: '))\n",
        "take_photo_and_process(filename='/content/drive/MyDrive/CS362V/data/faces/%s.jpg' % (name))\n",
        "\n",
        "try:\n",
        "  with open(\"/content/drive/MyDrive/CS362V/data/data.pkl\", \"rb\") as data_file:\n",
        "    existing_data = pickle.load(data_file)\n",
        "except FileNotFoundError:\n",
        "    existing_data = {}\n",
        "\n",
        "existing_data.update(processPhoto(\"%s.jpg\" % (name)))\n",
        "\n",
        "with open(\"/content/drive/MyDrive/CS362V/data/data.pkl\", 'wb') as data_file:\n",
        "    pickle.dump(existing_data, data_file)"
      ],
      "metadata": {
        "id": "rsjDqTNZ9CWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove a face from accepted faces:"
      ],
      "metadata": {
        "id": "Wi-8YmNYEpGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to process the photo using OpenCV\n",
        "def process_photo(filename):\n",
        "\n",
        "    full_path = os.path.join('/content/drive/MyDrive/CS362V/data/faces', filename)\n",
        "\n",
        "    # Load the cascade\n",
        "    face_cascade_name = '/content/drive/MyDrive/opencv/data/haarcascades/haarcascade_frontalface_alt.xml'\n",
        "    face_cascade = cv.CascadeClassifier()\n",
        "\n",
        "    if not face_cascade.load(cv.samples.findFile(face_cascade_name)):\n",
        "        print('--(!)Error loading face cascade')\n",
        "        return\n",
        "\n",
        "    # Read the image using OpenCV\n",
        "    frame = cv.imread(full_path)\n",
        "\n",
        "    if frame is None:\n",
        "      print(f'--(!)Error reading image: {filename}')\n",
        "      return\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "    frame_gray = cv.equalizeHist(frame_gray)\n",
        "\n",
        "    # Detect faces\n",
        "    faces = face_cascade.detectMultiScale(frame_gray, 1.1, 4)\n",
        "\n",
        "    if len(faces) > 0:\n",
        "      x1, y1, width, height = faces[0]\n",
        "    else:\n",
        "      x1, y1, width, height = 1, 1, 10, 10\n",
        "\n",
        "    x1, y1 = abs(x1), abs(y1)\n",
        "    x2, y2 = x1 + width, y1 + height\n",
        "\n",
        "    gbr = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
        "    gbr = Image.fromarray(gbr)\n",
        "    gbr_array = np.asarray(gbr)\n",
        "\n",
        "    face = gbr_array[y1:y2, x1:x2]\n",
        "\n",
        "    face = Image.fromarray(face)\n",
        "    face = face.resize((160,160))\n",
        "    face = np.asarray(face)\n",
        "\n",
        "    face = np.expand_dims(face, axis=0)\n",
        "    signature = facenet_model.embeddings(face)\n",
        "\n",
        "    database[os.path.splitext(filename)[0]] = signature\n",
        "\n",
        "rm_name = str(input(\"Enter the first name of the face you would like to remove: \"))\n",
        "file_path = '/content/drive/MyDrive/CS362V/data/faces/%s.jpg' % (rm_name)\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    try:\n",
        "        os.remove(file_path)\n",
        "        print(f\"'{rm_name}' has been successfully removed.\")\n",
        "    except OSError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "else:\n",
        "    print(f\"'{rm_name}' does not exist.\")\n",
        "\n",
        "database = {}\n",
        "for filename in os.listdir('/content/drive/MyDrive/CS362V/data/faces'):\n",
        "  process_photo(filename)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/CS362V/data/data.pkl\", \"wb\") as data_file:\n",
        "  pickle.dump(database, data_file)"
      ],
      "metadata": {
        "id": "ZWz1EfT5iCUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify current user's face:"
      ],
      "metadata": {
        "id": "6C2aIPHTJMic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/CS362V/data/data.pkl\", \"rb\") as data_file:\n",
        "  database = pickle.load(data_file)\n",
        "\n",
        "def take_photo_and_process(filename='photo.jpg', quality=0.8):\n",
        "    # JavaScript code to take a photo after 3 seconds\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "            document.body.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            // Wait for 3 seconds before capturing the photo\n",
        "            await new Promise((resolve) => setTimeout(resolve, 5000));\n",
        "\n",
        "            // Capture the photo\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "            // Stop the stream and remove video element\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            video.remove();\n",
        "\n",
        "            // Return the photo data URL\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "\n",
        "    # Display the JavaScript code and capture the photo\n",
        "    display(js)\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "\n",
        "    # Save the photo to a file\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "\n",
        "    # Process the photo using OpenCV\n",
        "    process_photo(filename)\n",
        "\n",
        "# Define the function to process the photo using OpenCV\n",
        "def process_photo(filename):\n",
        "\n",
        "    # Load the cascade\n",
        "    face_cascade_name = '/content/drive/MyDrive/opencv/data/haarcascades/haarcascade_frontalface_alt.xml'\n",
        "    face_cascade = cv.CascadeClassifier()\n",
        "\n",
        "    if not face_cascade.load(cv.samples.findFile(face_cascade_name)):\n",
        "        print('--(!)Error loading face cascade')\n",
        "        return\n",
        "\n",
        "    # Read the image using OpenCV\n",
        "    frame = cv.imread(filename)\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "    frame_gray = cv.equalizeHist(frame_gray)\n",
        "\n",
        "    # Detect faces\n",
        "    faces = face_cascade.detectMultiScale(frame_gray, 1.1, 4)\n",
        "\n",
        "    if len(faces) > 0:\n",
        "      x1, y1, width, height = faces[0]\n",
        "    else:\n",
        "      x1, y1, width, height = 1, 1, 10, 10\n",
        "\n",
        "    x1, y1 = abs(x1), abs(y1)\n",
        "    x2, y2 = x1 + width, y1 + height\n",
        "\n",
        "    gbr = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
        "    gbr = Image.fromarray(gbr)\n",
        "    gbr_array = np.asarray(gbr)\n",
        "\n",
        "    face = gbr_array[y1:y2, x1:x2]\n",
        "\n",
        "    face = Image.fromarray(face)\n",
        "    face = face.resize((160,160))\n",
        "    face = np.asarray(face)\n",
        "\n",
        "    face = np.expand_dims(face, axis=0)\n",
        "    signature = facenet_model.embeddings(face)\n",
        "\n",
        "    min_dist = 100\n",
        "    identity = \"\"\n",
        "    for key, value in database.items():\n",
        "      dist = np.linalg.norm(value - signature)\n",
        "      if dist < min_dist:\n",
        "        min_dist = dist\n",
        "        identity = key\n",
        "\n",
        "    # Determine whether the face is recognized\n",
        "    recognition_threshold = 1\n",
        "    print(min_dist, recognition_threshold)\n",
        "    if min_dist <= recognition_threshold:\n",
        "        welcome_text = f'Welcome, {identity}.'\n",
        "        text_color = (0, 255, 0)\n",
        "    else:\n",
        "        # If the minimum distance exceeds the threshold, the face is not recognized\n",
        "        welcome_text = 'Not Verified.'\n",
        "        text_color = (0, 0, 255)\n",
        "\n",
        "    cv.putText(frame, welcome_text, (50, 50), cv.FONT_HERSHEY_SIMPLEX, 1, text_color, 2)\n",
        "    cv.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 205), 2)\n",
        "\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "take_photo_and_process()"
      ],
      "metadata": {
        "id": "-gg3fY96kW5w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}